## 事务隔离的等级

脏读：读到另外一个失误没有被提交的数据，没有提交的数据可能会回滚导致单当前数据过时。

不可重复读取：前后两次读同一个数是的不一样

幻读：两次读取的数量不一样

自种隔离级别来避免这种现象，级别低到高，效率高到低：

读未提交read uncommitted: 还没提交的变更也会被看到。脏读，不可重复读，幻读

读提交read committed: 提交后做的变更才会被看到。不可重复读，幻读

可重复读repeatable read: 执行过程中看到的数据一直根启动时是一样的。Innodb默认的。幻读

串行化，serializable: 记录加锁，后面的等前面完成，一次执行，不交叉

事务是在引擎层实现的，innoDB支持事务。

## 事务的四大特性

transaction

是有innodb引擎来支持的，不是所有引擎都支持事务。

原子性：要么全部完成，要么全部不完成。发生问题，回滚。

一致性：操作前操作后，不会有计算不对的地方。结果是准确的

隔离性：允许多个失误同时进行读写修改，隔离性防止交叉执行导致数据混乱。不回干扰有独立的数据空间。

持久性：修改是永久的，不会丢失。


## sql查询语句是怎么执行的
1. 连接器：和客户端进行三次tcp握手建立连接，校对客户端用户名和密码，核对成功，读取该用户权限，设置权限约束后面的行为。
2. 查询缓存：查询语句：结果。8.0之后没有缓存了，很低效。 如果命中直接返回，否则继续执行。
3. 解析SQL，解析器，词法分析和语法分析，构建语法树给后续执行使用。
4. 执行SQL，
   - 预处理，拓展select* 的*。检查表或者字段是否存在。
   - 优化器，制定执行方案。eg 使用哪个索引，考虑成本。有表关联的话决定表的连接顺序
   - 执行器，执行器和存储引擎交互，从存储引擎读取记录返回客户端。
       - 主键索引查询
       - 全表扫描
       - 索引下推


## select/poll/epoll
让一个进程高效管理多个io链接，而不是每个链接创建一个阻塞的进程。
select function allows process to instruct kernel to wait for any one of events to occur and wake up the process.
eg any dexriptors in the set{1, 4, 5}. We tell the kernel what descriptors we are interested eg reading, writing or exception, and how long to wait.
Not only socket any descriptor can be tested using select. `Qint select(int maxfdp1, fd_set *readset, fd_set *writeset, fd_set *exceptset,
const struct timeval *timeout);` You can specify select to wait for a limited time. It is normally disrupted if the process
catches a signal. It may return an error of ETNTR if catching a signals. timeout is not accurate. readset, writeset and exceptset
specify descriptors that we want to kernel to test for. only two exception supported. 

how to specify descriptors for each of these arguments - descriptor sets, an array of integers.
eg 32 bit integers, each bit represents a descriptors, 0-31, second element is 32 - 63. 
Details is hidden in fd_set `void FD_SET(int fd, fd_set *fdset);` select is value result argument.
## linux如何查看一个进程，杀死进程，查看端口被占用
查看进程：ps 当前这个terminal展开的进程。

终止进程：kill pid 默认发送term。 kill -9 强制终止，不能被忽略。kill还可以发送其他信号。

ps aux: 所有用户进程，有很多。

查看端口：lsof -i :8080 查看什么应用8080端口。lsof: list open files， 展示什么文件资源被打开了。
lsof -i：表示所有internet链接，网络相关的文件。
## linux命令

chomod - change mode

## 从输入 URL 到页面展示到底发生了什么？

todo: 细节还不熟悉

第一步：对url解析生成发给web的请求。URL实际上是服务器里的文件资源。浏览器会解析url生成HTTP请求。

DNS解析，真实地址查询：生成完HTTP消息后，委托操作系统把消息发送给web服务器。需要提供通信对象的IP地址。DNS服务器保存了web服务器域名和IP的对应。发生DNS解析。
浏览器会调用操作系统的DNS解析函数。 .是根域名，.com是顶级域，server.com权威域。任何dns服务器都可以找到根域名，通过跟域名找到目标。 
路由器缓存-本地host文件-dns服务器-根dns

协议栈：操作系统。DNS获取到IP后把工作交给协议栈。获取到ip地址后，浏览器调用socket库，委托协议栈负责收发数据。

可靠传输TCP: 三次握手保证双方都有发送和接收的能力。HTTP消息太大超过MSS，TCP会把HTTP拆成小块。MTU包含IP头，TCP头数据的最长长度。MSS去头部。
TCP包含的一些信息：端口，包的序列号，窗口大小为了做流量控制，TCP还会控制自己不发太快。HTTP传输前三次握手。组装TCP
头部HTTP头部和数据给下一层。

远程定位IP:TCP发送都需要IP模块把数据封装成网络包。IP协议里要有源地址和目标IP。

两点传输MAC: 

TCP四次挥手断开，浏览器渲染页面。

## TCP/IP模型和OSI模型的区别
todo: 说一下每层作用，熟悉每层的作用用途

都是用来研究网络通信的框架。

OSI：是ISO国际标准组织提出的，先设计出来，希望大家去实现具体的协议。有7层，应用层，表示层（加密，格式转化），会话层（维持会话状态），传输层，网络层，数据链路层，物理层。便于学习理解，是一个理想的蓝图。


TPC/IP是实际互联网运行的标准。先有的IP，TCP协议跑通后才归纳出来的分层模型。是实践的总结。

应用层：应用数据，应用层把数据传给传输层。应用层的功能http, ftp, telnet, DNS。应用层在用户态，其他的在内核态。

传输层：TCP头+应用数据 应用间数据传输的媒介。接收应用层数据包。有两个协议：TCP UDP。大部分应用用的tcp，HTTP用的也是tcp。有流量控制，超时重传保障数据传输可靠。
UDP只负责发数据包，不保证抵达，传输效率高。TCP段：传输数据被切成数据报分块。中途丢失的会重新发送，而不是发送整个数据报。MSS，TCP最长的报文长度。传输层负责把数据报传给应用。区分设备上同时
多个应用传输数据，用端口分开。80web服务器。传输报文会带端口。

网络层： IP头TCP头应用数据 负责实际传输工作。IP internet protocol.将传输层报文加上IP头部。太长了会再次本片。这是要发送给网络的IP报文。
怎么去找设备。这是IP的**寻址**能力。给每个设备IP地址。IP地址有两种意义：有网络号，IP属于哪个子网；主机号，同一个子网下的不同主机。
IP协议另外一个能力是**路由**。数据报达到一个节点要通过**路由算法**决定下一步怎么走。**路由器的工作**找到目标子网，把数据报发过去。IP寻址
告诉我们下一个方向朝哪，路由选择路径

网络接口层：帧头MAC头IP头TCP头应用数据帧尾 IP头部生成后交给网络接口。IP前加上MAC封装成data frame发到网络上。通过以太网寻址需要MAC地址。网络接口层为
网络层提供链路级别传输link级别，负责以太网Wi-Fi底层网络上发送原始数据报。送到网线另外一头的网卡上。

## 页面置换的算法
todo: 流畅一点说快一些
标准：内存被占满了，考虑把哪些页表放回磁盘。最佳页面置换法。置换未来最长时间不访问的页面。理想状态不可能达到，参考提供算法效率。

先进先出：驻留时间最长的先被置换出去。简单实现的。

最近没使用的：最长时间没被访问过的页面，他觉得过去很久没用未来也不会用。维护时间戳代价很高，还要去找那个最老的

时钟页面置换：访问位是0就删除替换，表针前走一位；1表示是新来的。访问位是1设置成0表针提前。直到找到访问位0.linux分成两部分。

最不常用：选择访问次数最少的页面将其淘汰。对页面设置一个计数器，被访问+1. 问题，加计数器有硬件成本，通过链表差最小值很耗时，只考虑历史频率不考虑时间
最近频繁访问的页表会被误伤。可以设置时钟中断把过去记录设置成1.

## 线程同步的方式
todo：信号量说明一下阻塞的情况，条件变量描述简单直接一些。sem <=0会唤醒,signal会发送信号唤醒一个线程。说的不对
锁，信号量，读写锁，

条件变量：必须和互斥锁绑在一起，确保没人同时修改状态。检查条件如果不符合就会ptherad_cond_wait(&cond, &mutex)原子操作会释放锁，阻塞，被唤醒后重新抢锁。pthread_cond_broadcast/signal
唤醒等待里的一个线程。signal 会发送信号，OS唤醒一个等待队列的线程，这个线程先拿到锁才能继续执行。如果没有等待的，这个信号会被OS忽视。

```
// 定义锁和条件变量
pthread_mutex_t mutex;
pthread_cond_t cond_not_full;  // 条件：缓冲区不满 (给生产者用)
pthread_cond_t cond_not_empty; // 条件：缓冲区不空 (给消费者用)

// 初始化锁和条件变量
    pthread_mutex_init(&mutex, NULL);
    pthread_cond_init(&cond_not_full, NULL);
    pthread_cond_init(&cond_not_empty, NULL);
```

## 虚拟内存
动机：如果没有内存的抽象，物理内存完全暴露给应用，那一个程序可以轻易分把内存情况。没有隔离保护机制，进程之间也容易
篡改别人的内容。对于程序直接引用物理地址，这是我们绝对要避免的事情。所以，操作系统会给每个进程分配一套虚拟地址，让
他们之间互不干涉， 阻止他们直接访问物理地址。 虚拟地址到物理地址的映射工作就交给了操作系统。
允许程序使用比实际内存更大的空间，每个程序有足够的内存运行。

进程都不能访问到物理地址，虚拟地址到物理地址对于程序来说是透明的。虚拟地址通过MMU映射到物理地址。
有两种方式，内存分段：不同的段有不同属性eg代码分段，堆栈。虚拟地址被分成4个段。问题是内存碎片。应为没有连续的内存空间，哪怕释放了也无法被利用。
可以把一段存进磁盘在读出来。这样内存交换率是很低的。

MMU：进程访问的虚拟地址通过CPU的MMU单元先映射到物理地址，cpu实际访问的物理地址。

分段内存：

一份虚拟地址，分段成逻辑快块比如堆栈，代码，数据。分段下的虚拟地址高位是段的selector, 里面有段号
对应段表的一列。这里有段实际的物理基座地址。低位是段内的偏移量哪一行。基座地址和offset相加判断有没有越界。

问题：
- 会有外部内存碎片。不会内部内存碎片，根据需求分配的内存，不会剩余很多。长度都不一样，小概率恰好，一部分内存释放正好可以分给别人。
会产生很多不连续内存。无法分配给其他程序用到。

- 内存交换。解决碎片，可以把程序往磁盘里写空出连续的空间，然后在读回来。磁盘里有专门的内存交换空间。对于分段的方式，出现碎片，我们不得不进行交换，
  这个过程就会产生性能瓶颈，因为磁盘操作很慢。

内存分页：

可以避免内存碎片，和内存交换费时的问题。把整个虚拟内存和物理内存切成固定尺寸大小。每一个框是一页。虚拟和物理通过段表映射，页表在内存里
MMU里进行转换。如果页表不存在就会

问题： 程序不需要一页也会强制分配一页，会有内部内存碎片。

内存交换效率高： 会把不经常访问的页表释放出来写在硬盘上，每次只写几页。通过分页，不会一次性把程序加载到物理内存。用到的
死后才会把指令数据加载进去。

虚拟地址的结构： 高位是页号，是页表的索引。页表一行对应实际的物理地址，和偏移量做相加就是最终的地址。

问题：对进程的页表太多了。

多级页表：解决页表多的方法。一级页表映射2级页表，一条映射1024项。一级页表覆盖掉全部覆盖掉内存空间，🎧页表在需要时在
创建。64位的系统对应4级。

TLB：分级页表导致地址的转换工序变多了。TLB里面缓存访问多的页表。TLB在MMU旁边。寻址会先查TLB。

段页式内存：
代码段里面分页，栈段，数据段。先按逻辑意义分段，在每个段分成多个页。地址有段号页号和位移组成。段表一行对应页表，页表对应物理地址。


## 锁的种类

背景：多线程访问共享资源避免不了竞争情况，为了解决这个问题，我们都会在访问共享资源之前给它加个锁。

加锁的目的：保证共享资源在任一时间只有一个线程访问，避免数据错乱。

最底层的两种锁：互斥锁和自旋锁。当一个线程加锁后，另外一个线程重复加锁就会失败。这两个的失败处理方式不一样。

互斥锁加锁失败后，线程会释放cpu切换给其他线程运行, 线程会被内核设置成睡眠状态，等锁被释放后，内核会再把它唤醒，成功获取锁后就可以继续执行了。
这里的开销就是1. 内核把线程从运行设置到睡眠，然后切换cpu给别的进程。2. 锁被释放后，切换睡眠状态到就绪状态再切换cpu的时间。会发生的问题就是上下文切换的时间比锁住进程执行的时间还要长。
性能消耗大。

自旋锁失败后，线程会忙着等待知道它拿到锁。 通过CPU CAS函数，在用户态里完成加锁和解锁操作。开销相对少一些。加锁的两个步骤1: 查看锁的状态，如果空闲进行第二部 2: 把锁设置成当前进程持有
这两个指令被cas函数和为一个原子指令 - 一次性完成所有步骤，要么都不执行。加锁失败的线程可能会忙等待，知道它拿到锁，像是while 循环。自旋锁不会放弃cpu所以，单核cpu需要抢占式
的调度器中断它让其他线程运行。自旋和被锁代码执行时间成正比的，这个时间自旋线程会一直占用cpu。

总结：面对加锁失败，一个用线程切换，一个用忙等待带对应。这是锁最基本的形态，别的是衍生。

读写锁：读取资源用读锁，修改资源用写锁，区分读写操作。

工作原理：
- 写锁没被持有时候，任何多线程都可以持有读锁访问资源，这很有道理因为读不会破坏资源，这样可以提高读的效率。
- 一旦写锁被持有，获取读锁和写锁都会被阻塞。
写锁是独占的，读锁是共享的。

更细分为：
- 读优先锁：如果有线程在读，别的写线程会被阻塞，过程中还可以加别的读锁。写线程会造成饥饿现象
- 写优先锁：获取锁的时候，有线程在读，会等他读完，然后写线程成功获取锁，中间有别的读线程获取锁会被阻塞。

更公平一点，用一个列队让他们排队谁也不回饥饿。

上面都是悲观锁假设冲突概率高。

乐观锁与悲观锁：冲突概率很低的情况下，乐观锁实用。它让你先修改资源结束后在验证有没有冲突。如果没有操作完成，有的话就放弃这次操作。放弃之后可以再重试这次操作。
就像git用了乐观锁，发生冲突后要我们自己修改完提交。乐观锁完全除去加锁解锁的操作，但是发生冲突后重试成本高。

加锁的颗粒度要小。

## 死锁
todo: java jstack

背景：为了防止多线程竞争共享资源导致数据混乱，我们会给共享资源加上互斥锁，只有成功得到锁的线程才能操作资源，没拿到的线程要乖乖等待。

这会导致的问题： 有一种情况两个线程都在等待状态等对方释放锁，没有外力，就会一直等待，这就是死锁。两个或者以上并发

解释死锁：互斥性，多个线程不可以同时使用一个资源。 不可剥夺，在使用完前不会被其他线程获取到。 环路，a-1 b-2 a等2 b等1 持有并等待：线程在等待的时候并不会释放资源

排查死锁：java jstack, 显示程序执行堆栈信息，如果一直没有变动大概率是死锁因为在等待锁

避免死锁： 
- 避免死锁会发生的情况。打破环路，将资源有序分配，打破死锁，都要遵循先获取a 在获取b的顺序不可以反着来
  
## 进程的同步和互斥
todo: 增加同步说明， 目的除了数据混乱问题，还有生产消费同步问题。例子有点啰嗦。了解哲学家吃面哪一段代码。

多个线程竞争共享资源会导致共享数据混乱。**竞争条件 race condition** 在操作过程中发生上下文切换，导致结果不确定。多进程同样会有这种情况。

方法：
**临界区 critical section** 共享代码片段，一定不能给多个线程执行。这段代码是**互斥 mutual exclusion**
**线程/进程同步**希望线程按一定顺序执行，相互等待互相通信。
**锁** 加锁解锁
    - 忙等锁：一直获取不到锁一直在while里面等，spin lock. 自旋会一直利用cpu周期，需要抢占是调度器time interrupt把控制权交给别人。
    - 无忙等锁：不用自旋，放到等待队列里把线程设置成等待状态

使用testAndSet()实现忙等锁

**信号量** P、V，比锁更多能一点可以实现同步和互斥，通常表示资源的数量，对应一个整型。
- P -1, if sem<0, 进程进入阻塞状态，会阻塞
- V +1 if sem <=0, 唤醒一个等待进程，V不会阻塞
- P V 是由操作系统实现的，具有原子性，P V包裹临界区域

信号量实现互斥 Semaphore s = 1；1 表示没有线程在，0表示有一个线程在，-1 表示一个线程在临界区，另一个在等待

生产者消费者问题：

实现同步 初始0；

## 用户态和内核态

为避免用户程序直接进行硬件操作，这样很危险内存磁盘可能都会被改掉。所以程序实际上通过操作系统的内核这一桥梁来链接硬件设备。内核是操作系统的核心部分，它
有很高的权限。操作系统会把内存分成两个区域。内核空间给内核程序用，用户空间给应用程序用。内核有很高的权限，这里的代码可以访问
所有的内存空间，但是用户空间的不可以。当程序使用用户空间的时候，在用户态。使用内核空间是在内核态。这两种状态是可以切换到。如果程序要切换到内核态去往磁盘里写东西，
它可以中断当前的用户程序通过中断指令trap跳到去处理中断程序，开始内核态的工作。内核处理完会把cpu执行权返还给用户程序。 

内核里面做的事情有：
- 管理进程，线程，调度，决定哪个进程被cpu处理
- 管理内存，分配和回收
- 硬件设备，进程和硬件之间的用信能力
- 系统调用，应用程序可以通过系统调用获得更高运行权限

进入内核态的方式
- 系统调用，主动进入比如read命令
- 运行错误，cpu自动切换到内核态
- 外部的中断如时钟中断

用户态下，cpu只能和执行部分指令，无法直接访问硬件资源。内核态下，cpu可以执行左右指令访问所有资源。

## 并发和并行
一段时间可以执行多个任务是并发，单核cpu实际是快速切换的执行，但是程序感知不到。时间遍轮转，调度机制切换任务

同时处理多个任务需要多核cpu，这就是并行。并行的单个cpu上也可以有并发。

并行不一定比并发更快。并发主要是拉满一个cpu的利用率，一有阻塞就换任务。考虑io等待的操作用单线程并发更好。把任务分配给不同cpu是耗费时间的。

## 进程和线程之间有什么区别
<details>

进程和线程的定义区别：
在操作系统里面，进程就是一个正在执行的程序. 当我们在电脑上打开很多程序的时候，操作系统就会同时创建了许多的进程。可以理解为是资源分配的最小单位，因为操作系统会给每一个进程分配独立的内存空间，配置输入输出流等等运行这个程序需要的所有资源。所以在进程实际是一种数据结构，记录内存地址，CPU寄存器值，虚拟地址，进程的状态等等，这个数据结构就是PCB进程控制快。与之对比的是线程。这里在一个包含的关系，进程之下可以运行一条或者多条线程。可以想一下一份代码从上到下的运行到结尾。
下一行等着上一行运行结束再执行，这是一条线程。另一种就是多线程。统一分代码不同的方法他们俩就分开运行，各自不依赖对方，这也能提高效率。线程是cpu最小的调度单位，它包换cpu执行要的代码，寄存器，计数器，多余的就没有了。这也是每个线程独立的信息。

如果程序只执行一个流程代表他是单线程的，有多个执行流程就是多线程，线程是调度的基本单位。线程之间代码，堆空间，打开的文件是共享的，栈和寄存器是独有的。

效率区别：
和进程的区别就是。计算机不会为线程分配那么多资源。如果一个进程中有很多线程在运行，这些线程会共享一个进程的虚拟内存。这包括代码、文件、全局变量，文件的管理等，但他们也有一部分独立的东西。比如寄存器， 栈。所以计算机在创建线程时比进程简单，因为它不需要开辟新空间，很多资源各个线程之间共享，同理在销毁，创建的时候县城需要创建和释放的资源就比进程要少。所以线程比进程更有效率。但是相对来说，安全性没有那么高。进程的失败不会影响别的进程但是线程就会。

上下文切换区别：
我们需要进程和县城的目的都是想并发的执行程序。为了提高CPU的利用效率，让CPU执行这个程序一段时间，然后执行别的程序一段时间再来执行这个，而不是卡死在一个程序当中. 这个切换的过程需要频繁上下文切换. 进程和现成的上下文切换也有不同的特性。晋城之下的上下文切换。计算机需要替换的东西就比线程要多，除了CPU的寄存器和程序技术，这是进程和县城都有的，进程还需要替换比如页表，文件。因为每个进程独有的一份不一样的。上下切换的时候这些资源都需要替换。但是在线程里只需要替换不共享的部分。

通信区别：
再说一下关于进程间通信和线程之间的通信。
进程间的通信比较麻烦，一般需要借助内核空间，因为内核是管理进程的更上一个层级系统。一种方式就是在内核中的管道沟通就是grep。一个进程可以向管道的一端发送消息，另外一个进程从另外一段收到消息，还有一种方式是消息对立，因为管道是没有格式化的自节流管道命令，对于这一点是一个提升用户可以发送自定义的数据结构，这个时候就需要发送者和接收，提前商定好这个内容格式，还有一种通信方式就是通过内核的存储空间进程共同访问存储空间通过里面读写数据来实现交流。这里举例三种方式县城之间的沟通交流就来得简单很多，因为本来他们就会共享内存，所以可以通过使用全局变量互通

并发操作要注意的问题：
不管是多个线程还是多个进程，在访问同一个资源的时候都需要特殊处理，防止竞争条件和考虑并发一致性的问题。我举几个处理的例子一个就是信号量在C语言里面是semaphore，他的概念是一个全局的计数器能，控制访问有多少进程或者线程正在访问这个资源，还提供这两个系统原子性操作P和V保证并发的安全。


Process is OS's abstraction of a running program. When we run multiple program at the same time, multiple processes
are run concurrently on the same system. Instructions of one process are interleaved with instructions of another process.
This is achieved by mehcanism known as context switching. A uniprocessor system only execute one program code at a time, while multicore can execute
several programs simultaneously. Processes abstracts over processor, main memory, IO devices.

Threads: a rpcess can consist of multiple threads, each running in the contect of the process, share same code and global data. 
Easier to share data between threads and more efficient. Multiple control flow within a process.

concurrency: a system with multiple, simultaneous activities. interleaving execution.

parallelism: use of concurrency to make system run faster. multiple processes running different cores.
- thread level paralellism

  Multicore processors: have several cpus or cors.

  hyperthreading: allows a single cpu to execute multiple threads/ flows of control.

instruciton level parallelism
  - processors execute multiple instructions at one time

</details>

## 进程间的通信
<details>
  管道：匿名管道，一种先进先出的内核文件，进程创建之后可以有读写的描述符进行读写消息，这种匿名的只可以从父进程继承多来，创建的时候把文件给儿子。命名管道，创建一个文件，可以通过文件名使用它，任意进程都可以使用。数据存储在内核里面。
  效率不高。
  
  队列：创建内核中的队列，可以自定义数据结构，需要接受和发送达成一致。这个发送接收消息都是一次系统调用要切换用户态和内核态，开销比较大。
  
  共享内存：本来虚拟地址到物理地址的映射不一样的，一个虚拟空间映射到相同的物理内存里面，不需要一直拷贝。

  信号量：共享内存会有冲突，资源竞争的问题。保证并发的一致性，信号量是一种方式。编程用的semaphore。它一个特殊的计数器，规定这个资源能同时被多少人用，也可以达到程序互斥的目的，
  P操作是-1, V操作是+1，这两个都是原子操作。信号量初始化为1，使用时候做P -1 的操作，<=0表示被占有。 V释放后<0 还有其他在等待，可以唤起。>0表示没有阻塞。0是同步信号，

  信号：处理异常的情况。kill -9 发送编号9的信号给一个进程，用来立即结束它。可以查看具体有几十种信号。有这个信号，系统或者程序收到后做对应的造作，比如终止进程，信号处理函数。

  socket: 跨网络通信。创建socket配置不同网络的通信方式。常见在客户端和服务端之间。可以配置基于TCP/IP字节流或者UDP数据报不同类型或者本地通信的socket。他们的编程模式不一样。tcp有三次握手。
  
</details>
